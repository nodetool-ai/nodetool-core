# User Management & Persistent Storage Implementation

## Overview

Implement multi-user bearer token authentication system for ALL deployment types (Docker, Root, GCP, RunPod) with persistent disk storage.

## Tech Design

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Management API                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /api/users/*                                    â”‚
â”‚  â”œâ”€ GET /api/users/ (admin only)               â”‚
â”‚  â”œâ”€ GET /api/users/{username} (admin only)        â”‚
â”‚  â”œâ”€ POST /api/users/ (admin only)              â”‚
â”‚  â”œâ”€ POST /api/users/reset-token (admin only)      â”‚
â”‚  â””â”€ DELETE /api/users/{username} (admin only)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           â†“ (HTTP Bearer Token)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               MultiUserAuthProvider                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Verify token against SHA256 hashes    â”‚  â”‚
â”‚  â”‚  Return user_id and role            â”‚  â”‚
â”‚  â”‚  User caching for performance          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (Read users.yaml)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              users.yaml (SHA256 hashed)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  admin: user_admin_xxx...          â”‚  â”‚
â”‚  â”‚    role: admin, token_hash: ...      â”‚  â”‚
â”‚  â”‚                                      â”‚  â”‚
â”‚  â”‚  alice: user_alice_xxx...           â”‚  â”‚
â”‚  â”‚    role: user, token_hash: ...         â”‚  â”‚
â”‚  â”‚                                      â”‚  â”‚
â”‚  â”‚  bob: user_bob_xxx...               â”‚  â”‚
â”‚  â”‚    role: user, token_hash: ...          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“ (File: 0o600 permissions)

           â†“ (Via API for remote, CLI for local)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Deployment Types                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Docker   â”‚  Root   â”‚  GCP    â”‚  RunPod  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Volumes  â”‚  Direct  â”‚  GCS     â”‚  NetVol  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SSH      â”‚  SSH    â”‚  HTTP    â”‚  HTTP    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  API      â”‚  API    â”‚  API     â”‚  API     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

**Local User Management:**
```
nodetool users add alice --role user
  â†“
UserManager.add_user(username, role)
  â†“
Write to ~/.config/nodetool/users.yaml (0o600)
  â†“
Return plaintext token (only shown once)
```

**Remote User Management (ALL deployment types):**
```
nodetool deploy users-add my-deployment alice --role user
  â†“
Prompt: Enter admin bearer token ******
  â†“
APIUserManager.add_user(username, role)
  â†“
HTTP POST http://deployment-url/api/users/
  Authorization: Bearer ADMIN_TOKEN
  â†“
UserManager.add_user(username, role)
  â†“
Write to /workspace/users.yaml (on deployment host)
  â†“
Return plaintext token
```

**Token Authentication:**
```
HTTP Request: Authorization: Bearer 7xK9mN2p...
  â†“
MultiUserAuthProvider.verify_token(token)
  â†“
Load users.yaml
  â†“
Compute SHA256(token)
  â†“
Match against token_hash in users.yaml
  â†“
Return AuthResult(user_id, token_type=USER)
  â†“
Set request.state.user_id
```

### Storage Path Configuration

**For Local/Root Deployments:**
```yaml
persistent_paths:
  users_file: "/var/lib/nodetool/users.yaml"
  db_path: "/var/lib/nodetool/nodetool.db"
  chroma_path: "/var/lib/nodetool/chroma"
  hf_cache: "/var/lib/nodetool/hf-cache"
  asset_bucket: "/var/lib/nodetool/assets"
  logs_path: "/var/log/nodetool"
```

**For Docker Deployments:**
```yaml
persistent_paths:
  users_file: "/data/workspace/users.yaml"
  db_path: "/data/workspace/nodetool.db"
  chroma_path: "/data/workspace/chroma"
  hf_cache: "/data/workspace/hf-cache"
  asset_bucket: "/data/workspace/assets"

volumes:
  - "/data/workspace:/workspace"
  - "/data/hf-cache:/hf-cache"
```

**For GCP Deployments:**
```yaml
persistent_paths:
  users_file: "/workspace/users.yaml"
  db_path: "/workspace/nodetool.db"
  chroma_path: "/workspace/chroma"
  hf_cache: "/workspace/hf-cache"

storage:
  gcs_bucket: "nodetool-persistent"
  gcs_mount_path: "/workspace"

container volumes:
  - mount GCS bucket at /workspace
```

**For RunPod Deployments:**
```yaml
persistent_paths:
  users_file: "/workspace/users.yaml"
  db_path: "/workspace/nodetool.db"
  chroma_path: "/workspace/chroma"

network_volume_id: "vol-xxxxxxxx"  # Persistent volume
# Volume automatically mounted at /workspace in all workers
```

### Security Model

**Token Security:**
- Generation: `secrets.token_urlsafe(32)` = 43 cryptographically secure chars
- Storage: SHA256 hash only (never plaintext)
- Expiration: Never (tokens valid until reset)
- File Permissions: `0o600` (owner read/write only)
- Display: Plaintext shown only on creation/reset (never after)

**Role-Based Access:**
- **Admin users:** Can access `/api/users/*` endpoints
- **Regular users:** Can only use `/api/*` (non-admin) endpoints
- **Admin enforcement:** Via `require_admin()` dependency on sensitive endpoints
- **Role detection:** Via `is_admin_user(user_id)` function

**API Security:**
- All user management endpoints require valid bearer token
- Admin-only endpoints require admin role
- Tokens validated against SHA256 hashes in users.yaml
- No token expiration (simplifies management for 1-10 users)

---

## Tasks Completed

### âœ… Phase 1: Core Auth Infrastructure

- [x] Create `MultiUserAuthProvider` in `src/nodetool/security/providers/multi_user.py`
- [x] Create `UserManager` in `src/nodetool/security/user_manager.py`
- [x] Add `PersistentPaths` model to `src/nodetool/config/deployment.py`
- [x] Register `USERS_FILE` setting in `src/nodetool/config/settings.py`
- [x] Add `USERS_FILE` to DEFAULT_ENV in `src/nodetool/config/environment.py`
- [x] Update `UserManager` to use `USERS_FILE` environment variable
- [x] Add `multi_user` to valid auth providers in environment
- [x] Add admin role enforcement in `src/nodetool/security/admin_auth.py`
- [x] Register `MultiUserAuthProvider` in providers `__init__.py`

### âœ… Phase 2: Deployment Configuration

- [x] Add `persistent_paths` field to `SelfHostedDockerDeployment`
- [x] Add `persistent_paths` field to `SelfHostedShellDeployment` (Root)
- [x] Add `persistent_paths` field to `RunPodDeployment`
- [x] Add `persistent_paths` field to `GCPDeployment`
- [x] Fix Union type syntax (use `|` operator for Python 3.10+)

### âœ… Phase 3: API User Management

- [x] Create API user routes in `src/nodetool/api/users.py`
  - [x] `GET /api/users/` - List users (masked tokens)
  - [x] `GET /api/users/{username}` - Get user info
  - [x] `POST /api/users/` - Add user (returns plaintext token)
  - [x] `POST /api/users/reset-token` - Reset user token
  - [x] `DELETE /api/users/{username}` - Remove user
- [x] All endpoints require admin role for multi_user auth
- [x] All endpoints return 501 for other auth providers
- [x] Create `AddUserRequest` and `ResetTokenRequest` models

### âœ… Phase 4: Remote User Management Client

- [x] Create `APIUserManager` in `src/nodetool/deploy/api_user_manager.py`
- [x] Implement `list_users()` - List all users via API
- [x] Implement `add_user(username, role)` - Add user via API
- [x] Implement `reset_token(username)` - Reset token via API
- [x] Implement `remove_user(username)` - Remove user via API
- [x] Use httpx.AsyncClient for async HTTP requests
- [x] Proper error handling with HTTP status codes
- [x] Works with ALL deployment types (no SSH dependency for cloud)

### âœ… Phase 5: CLI User Management

- [x] Local CLI commands: `nodetool users add/list/remove/reset-token`
- [x] Remote CLI commands: `nodetool deploy users-{add,list,remove,reset-token}`
- [x] Remote commands use API (works with all deployment types)
- [x] Prompt for admin bearer token for remote operations
- [x] Display plaintext tokens with warnings
- [x] Support `--json` output format
- [x] Support `--force` flag for destructive operations

### âœ… Phase 6: API Server Integration

- [x] Register `users.router` in API server
- [x] Import users.router in `_load_default_routers()`
- [x] Add to routers list for automatic inclusion

### âœ… Phase 7: Testing

- [x] Test user creation and listing
- [x] Test token validation (valid/invalid/empty)
- [x] Test admin role detection
- [x] Test file permissions (0o600)
- [x] Test environment variable configuration

---

## Tasks Remaining / TODO

### ğŸš§ Phase 8: Docker Volume Mounting

- [ ] Update `docker_run.py` `_generate_env()` to use `persistent_paths`
- [ ] Add volume mount generation function
- [ ] Set environment variables: `USERS_FILE`, `DB_PATH`, `CHROMA_PATH`, `HF_HOME`, `ASSET_BUCKET`
- [ ] Add support for custom `volumes:` field in deployment config
- [ ] Test Docker deployment with persistent volumes
- [ ] Verify data persists across container restarts

### ğŸš§ Phase 9: GCP Storage Mounting

- [ ] Update `deploy_to_gcp.py` to use GCS bucket mounting
- [ ] Mount GCS bucket at `/workspace` path
- [ ] Set environment variables from `persistent_paths`
- [ ] Create storage bucket if not exists
- [ ] Test GCP deployment with persistent storage
- [ ] Verify data persists across Cloud Run redeployments

### ğŸš§ Phase 10: RunPod Volume Configuration

- [ ] Update `deploy_to_runpod.py` to configure network volumes
- [ ] Set network volume mount at `/workspace`
- [ ] Set environment variables from `persistent_paths`
- [ ] Test RunPod deployment with persistent storage
- [ ] Verify data persists across worker scaling

### ğŸš§ Phase 11: Admin Route Integration

- [ ] Update admin routes to use `require_admin()` dependency
- [ ] Add admin checks to `/admin/collections/*` endpoints
- [ ] Add admin checks to `/admin/storage/*` endpoints
- [ ] Add admin checks to `/admin/db/*` endpoints
- [ ] Update deployment admin routes
- [ ] Test admin-only endpoint protection

### ğŸš§ Phase 12: Root Deployment Volume Configuration

- [ ] Document Root deployment persistent paths
- [ ] Add systemd service file generation
- [ ] Configure file permissions for `/var/lib/nodetool/`
- [ ] Test Root deployment persistence

### ğŸš§ Phase 13: Documentation

- [ ] Add deployment configuration examples to docs
- [ ] Document volume mount strategies for each deployment type
- [ ] Create migration guide from legacy `worker_auth_token`
- [ ] Document `USERS_FILE` environment variable
- [ ] Add troubleshooting guide for persistent storage issues

### ğŸš§ Phase 14: Error Handling & Validation

- [ ] Add validation for `persistent_paths` configuration
- [ ] Ensure all paths are absolute or well-known relative
- [ ] Warn if paths not accessible at deploy time
- [ ] Provide helpful error messages for volume mount failures
- [ ] Add health check endpoint for persistent storage

### ğŸš§ Phase 15: Security Hardening

- [ ] Add token rotation recommendations
- [ ] Add user activity logging (optional)
- [ ] Add rate limiting for user management APIs
- [ ] Implement token revocation (without user deletion)
- [ ] Add IP-based access control for admin endpoints (optional)

---

## Design Decisions

### Why Bearer Tokens Over Other Options

1. **Simplicity:** Easier to implement and debug than session management
2. **Stateless:** Server doesn't need to track sessions
3. **Performance:** Fast verification, no database queries for session lookup
4. **Compatibility:** Works with curl, httpx, any HTTP client

### Why No Token Expiration

1. **Small Teams:** 1-10 users can manage tokens manually
2. **Reset Functionality:** Users can reset tokens anytime
3. **Security Tradeoff:** Expiration adds complexity (refresh tokens, handling expired requests)
4. **User Experience:** Fewer "login required" prompts for small teams

### Why File-Based Users (Not Database)

1. **Simplicity:** No database schema changes needed
2. **Portability:** Easy to backup/restore users file
3. **Consistency:** Same approach across all deployment types
4. **Performance:** No database queries for user lookups
5. **Security:** File can be encrypted at rest

### Why SHA256 Hashing

1. **One-way Function:** Cannot reverse hash to get plaintext token
2. **Standard:** Widely used, well-understood security practice
3. **Fast:** Computationally inexpensive
4. **Fixed Size:** Consistent 256-bit hash size

### Why Admin Role System

1. **Fine-grained Access:** Can have regular users without full admin rights
2. **Audit Trail:** Can track which user made changes
3. **Safety:** Prevents accidental deletion by non-admins
4. **Multi-tenant Ready:** Foundation for future per-user isolation

---

## Configuration Examples

### Docker Deployment

**deployment.yaml:**
```yaml
deployments:
  production-docker:
    type: docker
    host: 192.168.1.100
    ssh:
      user: ubuntu
      key_path: ~/.ssh/id_rsa
    persistent_paths:
      users_file: "/data/workspace/users.yaml"
      db_path: "/data/workspace/nodetool.db"
      chroma_path: "/data/workspace/chroma"
      hf_cache: "/data/workspace/hf-cache"
      asset_bucket: "/data/workspace/assets"
      logs_path: "/data/workspace/logs"
    container:
      name: nodetool-app
      port: 7777
      gpu: "0"
    image:
      name: nodetool/nodetool
      tag: latest
      registry: docker.io

    # Environment variables set by deploy script:
    # USERS_FILE=/data/workspace/users.yaml
    # DB_PATH=/data/workspace/nodetool.db
    # CHROMA_PATH=/data/workspace/chroma
    # HF_HOME=/hf-cache
    # ASSET_BUCKET=/data/workspace/assets
    # AUTH_PROVIDER=multi_user
```

**Docker Run Command:**
```bash
docker run -d \
  --name nodetool-app \
  -p 7777:7777 \
  --gpus all \
  -v /data/workspace:/workspace \
  -v /data/hf-cache:/hf-cache \
  -e USERS_FILE=/data/workspace/users.yaml \
  -e DB_PATH=/data/workspace/nodetool.db \
  -e CHROMA_PATH=/data/workspace/chroma \
  -e HF_HOME=/hf-cache \
  -e ASSET_BUCKET=/data/workspace/assets \
  -e AUTH_PROVIDER=multi_user \
  nodetool/nodetool:latest
```

### Root (Bare Metal) Deployment

**deployment.yaml:**
```yaml
deployments:
  bare-metal-server:
    type: root
    host: 192.168.1.101
    ssh:
      user: root
      key_path: ~/.ssh/id_rsa
    persistent_paths:
      users_file: "/var/lib/nodetool/users.yaml"
      db_path: "/var/lib/nodetool/nodetool.db"
      chroma_path: "/var/lib/nodetool/chroma"
      hf_cache: "/var/lib/nodetool/hf-cache"
      asset_bucket: "/var/lib/nodetool/assets"
      logs_path: "/var/log/nodetool"
    port: 7777
    service_name: nodetool-server
    environment:
      PORT: "7777"
      USERS_FILE: "/var/lib/nodetool/users.yaml"
      DB_PATH: "/var/lib/nodetool/nodetool.db"
      CHROMA_PATH: "/var/lib/nodetool/chroma"
      HF_HOME: "/var/lib/nodetool/hf-cache"
      ASSET_BUCKET: "/var/lib/nodetool/assets"
      AUTH_PROVIDER: "multi_user"
```

**systemd Service:**
```ini
[Unit]
Description=NodeTool Server
After=network.target

[Service]
Type=simple
User=nodetool
WorkingDirectory=/opt/nodetool
Environment="PORT=7777"
EnvironmentFile=/etc/nodetool/environment
ExecStart=/opt/nodetool/.venv/bin/python -m nodetool.api.run_server
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

### GCP Cloud Run Deployment

**deployment.yaml:**
```yaml
deployments:
  gcp-production:
    type: gcp
    project_id: my-gcp-project
    region: us-central1
    service_name: nodetool-api
    storage:
      gcs_bucket: "nodetool-persistent-storage"
      gcs_mount_path: "/workspace"
    persistent_paths:
      users_file: "/workspace/users.yaml"
      db_path: "/workspace/nodetool.db"
      chroma_path: "/workspace/chroma"
      hf_cache: "/workspace/hf-cache"
      asset_bucket: "/workspace/assets"
      logs_path: "/workspace/logs"
    image:
      registry: us-docker.pkg.dev
      repository: us-docker.pkg.dev/my-project/nodetool
      tag: latest
    resources:
      cpu: "4"
      memory: "16Gi"
      concurrency: 80
      timeout: 3600
```

**Cloud Run Configuration:**
```yaml
container:
  name: nodetool-server
  resources:
    cpu: 4
    memory: 16Gi
    concurrency: 80
    timeout: 3600s
  volumeMounts:
    - name: persistent-storage
      mountPath: /workspace
  env:
    - name: USERS_FILE
      value: "/workspace/users.yaml"
    - name: DB_PATH
      value: "/workspace/nodetool.db"
    - name: CHROMA_PATH
      value: "/workspace/chroma"
    - name: HF_HOME
      value: "/workspace/hf-cache"
    - name: ASSET_BUCKET
      value: "/workspace/assets"
    - name: AUTH_PROVIDER
      value: "multi_user"
```

**GCS Bucket:**
```bash
# Create GCS bucket
gsutil mb gs://nodetool-persistent-storage

# Set lifecycle policy (optional - auto-delete old data)
gsutil lifecycle set gs://nodetool-persistent-storage/** 30d

# Verify bucket
gsutil ls gs://nodetool-persistent-storage/
```

### RunPod Serverless Deployment

**deployment.yaml:**
```yaml
deployments:
  runpod-cloud:
    type: runpod
    network_volume_id: "vol-xxxxxxxxxxxxxxxx"  # Create via RunPod UI
    persistent_paths:
      users_file: "/workspace/users.yaml"
      db_path: "/workspace/nodetool.db"
      chroma_path: "/workspace/chroma"
      hf_cache: "/workspace/hf-cache"
      asset_bucket: "/workspace/assets"
    image:
      name: nodetool/nodetool
      tag: latest
      registry: docker.io
    gpu_types:
      - "NVIDIA RTX 4090"
    workers_min: 0
    workers_max: 3
    idle_timeout: 60
    platform: linux/amd64
```

**RunPod Template:**
```json
{
  "name": "nodetool-template",
  "image": "nodetool/nodetool:latest",
  "env": [
    {
      "key": "USERS_FILE",
      "value": "/workspace/users.yaml"
    },
    {
      "key": "DB_PATH",
      "value": "/workspace/nodetool.db"
    },
    {
      "key": "CHROMA_PATH",
      "value": "/workspace/chroma"
    },
    {
      "key": "HF_HOME",
      "value": "/workspace/hf-cache"
    },
    {
      "key": "ASSET_BUCKET",
      "value": "/workspace/assets"
    },
    {
      "key": "AUTH_PROVIDER",
      "value": "multi_user"
    }
  ],
  "networkVolumeId": "vol-xxxxxxxxxxxxxxxx"
}
```

---

## Usage Examples

### Local User Management

```bash
# Add admin user (do this first!)
nodetool users add admin --role admin
# â†’ âœ… User 'admin' added successfully
# â†’ Bearer Token (save this - won't be shown again!):
# â†’ 7xK9mN2pQzr5T8vW3yXaF9bJ...
# â†’ User ID: user_admin_xxx
# â†’ Role: admin

# Add regular user
nodetool users add alice --role user
# â†’ Token: 9YqL7mN4qS...

# List users (tokens masked)
nodetool users list
# â†’ â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
# â†’ â”ƒ Username â”ƒ User ID           â”ƒ Role â”ƒ Token Hash        â”ƒ Created            â”ƒ
# â†’ â”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
# â†’ â”‚ admin    â”‚ user_admin_...  â”‚ admin â”‚ ba39a2a46cb96b... â”‚ 2025-01-02T16:... â”‚
# â†’ â”‚ alice    â”‚ user_alice_...   â”‚ user  â”‚ 9YqL7mN4qS...     â”‚ 2025-01-02T16:... â”‚
# â†’ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# Reset user token
nodetool users reset-token alice
# â†’ âœ… New token for 'alice' generated
# â†’ New Bearer Token (save this!):
# â†’ 5zR8kN5pT...
# â†’ âš ï¸  Previous token is now invalid

# Remove user
nodetool users remove alice --force
# â†’ âœ… User 'alice' removed
```

### Remote User Management (Docker Deployment)

```bash
# Add user to Docker deployment
nodetool deploy users-add my-docker bob --role user
# Enter admin bearer token: ******
# â†’ âœ… User 'bob' added to 'my-docker'
# â†’ Bearer Token (save this - won't be shown again!):
# â†’ 3WxR9kN6pS...

# List users on remote Docker deployment
nodetool deploy users-list my-docker
# Enter admin bearer token: ******
# â†’ Shows all users on my-docker deployment

# Reset token for user on Docker deployment
nodetool deploy users-reset-token my-docker bob
# â†’ New token for 'bob' on 'my-docker'

# API-based (works with ALL deployment types, even GCP/RunPod!)
curl -X POST \
  -H "Authorization: Bearer 7xK9mN2p..." \
  -H "Content-Type: application/json" \
  -d '{"username":"charlie","role":"user"}' \
  http://192.168.1.100:7777/api/users/
# â†’ {"username":"charlie","user_id":"user_charlie_xxx","role":"user","token":"9WxR9kN6pS...","created_at":"2025-01-02T16:..."}
```

### Remote User Management (GCP Deployment)

```bash
# Add user to GCP deployment (works over HTTP, no SSH!)
nodetool deploy users-add gcp-prod dave --role admin
# Enter admin bearer token: ******
# â†’ âœ… User 'dave' added to 'gcp-prod'
# â†’ Token: 2LmQ9kN7pS...

# List users on GCP deployment
nodetool deploy users-list gcp-prod

# Reset token on GCP deployment
nodetool deploy users-reset-token gcp-prod dave
```

### Remote User Management (RunPod Deployment)

```bash
# Add user to RunPod deployment
nodetool deploy users-add runpod-cloud eve --role user
# Enter admin bearer token: ******
# â†’ âœ… User 'eve' added to 'runpod-cloud'
# â†’ Token: 7QxL4mN9pS...

# List users on RunPod deployment
nodetool deploy users-list runpod-cloud

# Reset token on RunPod deployment
nodetool deploy users-reset-token runpod-cloud eve
```

---

## Security Considerations

### Token Management

1. **Token Storage:** SHA256 hashes only, never plaintext
2. **File Permissions:** 0o600 (owner read/write only)
3. **Token Display:** Plaintext shown only once (creation/reset)
4. **No Expiration:** Tokens valid until reset (simpler for small teams)
5. **Unique IDs:** Each user has unique `user_id` (user_{name}_{uuid_short})

### Admin Access

1. **Role Detection:** `is_admin_user(user_id)` checks multi_user provider
2. **Endpoints Protected:** `/api/users/*` require admin role
3. **Dependency:** `Depends(require_admin)` for admin endpoints
4. **Fallback:** Other auth providers return 501 for user management

### Persistent Storage

1. **Volume Mounts:** All deployments must mount persistent volumes
2. **Path Configuration:** Via `persistent_paths` in deployment config
3. **Environment Variables:** Set `USERS_FILE`, `DB_PATH`, `CHROMA_PATH`, etc.
4. **Container Ephemeral:** Never write to container filesystem without volume

### Network Security

1. **HTTPS Required:** For production deployments
2. **Token Transmission:** Never send plaintext over unencrypted channels
3. **Admin Token:** Treat admin bearer token like password
4. **API Access:** All user management requires valid bearer token

---

## Troubleshooting

### Common Issues

**Issue: "User management not available for current auth provider"**
- **Cause:** `AUTH_PROVIDER` not set to `multi_user`
- **Fix:** Set `AUTH_PROVIDER=multi_user` in environment or deployment config

**Issue: "Users file not found"**
- **Cause:** `USERS_FILE` path doesn't exist
- **Fix:** Check volume mounts, verify persistent_paths configuration
- **Local:** Fallback to `~/.config/nodetool/users.yaml`

**Issue: "Data lost after container restart"**
- **Cause:** Writing to container filesystem instead of mounted volume
- **Fix:** Ensure all paths are on persistent volumes
- **Verify:** Check `USERS_FILE`, `DB_PATH`, `CHROMA_PATH` environment variables

**Issue: "Invalid token" for newly created user**
- **Cause:** Using old token from cache
- **Fix:** Clear browser auth headers, use new token
- **Verify:** Check `users.yaml` contains correct token hash

**Issue: "Admin access required" for regular user**
- **Cause:** Attempting to access `/api/users/` endpoint
- **Fix:** Use an admin user's token
- **Note:** Regular users can still use `/api/workflows/` etc.

### Docker Deployment Issues

**Issue: Volume mount not working**
```bash
# Check if volume exists
docker volume inspect nodetool-workspace

# Check container mounts
docker inspect my-docker-container | grep -A 10 Mounts

# Verify path in container
docker exec my-docker-container ls -la /workspace
```

**Issue: Permission denied on users.yaml**
```bash
# Check file permissions
ls -la /data/workspace/users.yaml
# Should be: -rw------- (0o600)

# Fix permissions on remote
ssh user@host "chmod 0600 /data/workspace/users.yaml"
```

### GCP Deployment Issues

**Issue: GCS bucket access denied**
```bash
# Check service account permissions
gcloud iam service-accounts list

# Grant storage.admin role
gcloud projects add-iam-policy-binding my-project \
  --member serviceAccount:my-service@... \
  --role roles/storage.objectAdmin \
  --project my-project
```

**Issue: Data not persisting across redeployments**
```bash
# Check if data is in bucket
gsutil ls gs://nodetool-persistent-storage/

# Check bucket lifecycle policy
gsutil lifecycle get gs://nodetool-persistent-storage/

# Verify container mount
gcloud run services describe nodetool-api --format=json | grep volumeMounts
```

### RunPod Deployment Issues

**Issue: Network volume not attached**
```bash
# Check template network volume
curl -X GET \
  -H "Authorization: Bearer $RUNPOD_API_KEY" \
  https://api.runpod.ai/v2/templates/TEMPLATE_ID | jq '.networkVolumeId'

# List available volumes
curl -X GET \
  -H "Authorization: Bearer $RUNPOD_API_KEY" \
  https://api.runpod.ai/v2/networkVolumes
```

---

## Migration Guide

### From Legacy `worker_auth_token` (Single Token)

**Old Configuration:**
```yaml
# deployment.yaml (old)
worker_auth_token: "7xK9mN2p..."
```

**New Configuration:**
```yaml
# deployment.yaml (new)
persistent_paths:
  users_file: "/data/workspace/users.yaml"

# Or use environment variable
# AUTH_PROVIDER=multi_user
```

**Steps:**
1. Create initial admin user:
   ```bash
   nodetool users add admin --role admin
   # Save the token
   ```

2. Update deployment configuration to use `multi_user` auth

3. Deploy with persistent storage configuration

4. Old tokens will no longer work (expected behavior)

**Migration Benefits:**
- Multiple users with different roles
- Individual token management
- Better audit trail
- No need to share admin token

### From Local Development to Production

**Development (local):**
```bash
# Users in ~/.config/nodetool/users.yaml
nodetool users list
```

**Production (Docker/GCP/RunPod):**
```bash
# Users on remote persistent storage
nodetool deploy users-list my-deployment
# Enter admin bearer token
```

**Key Differences:**
- Development: Direct file access
- Production: API-based management with admin token
- Same CLI interface for consistency
- Different users file locations

---

## Performance Considerations

### User Management Performance

- **Token Verification:** O(1) hash lookup
- **User Listing:** O(n) where n = number of users
- **File Caching:** Users cached in `MultiUserAuthProvider` with modification time check
- **File I/O:** Only on user create/update/delete

### API Performance

- **Authentication:** Verified before endpoint logic runs
- **Admin Check:** O(1) role lookup
- **Response Size:** User objects with masked tokens (~200 bytes per user)

### Database Performance

- **No User Tables:** Users in file, no database queries
- **Reduced Locking:** No user table locks
- **Faster Queries:** No user joins for access control

### Network Performance

- **HTTP/HTTPS:** Depends on deployment type
- **Latency:** <50ms for local, <200ms for cloud
- **Overhead:** Single HTTP header for auth

---

## Testing Checklist

### Unit Tests

- [ ] `UserManager.add_user()` creates valid user
- [ ] `UserManager.add_user()` rejects duplicate username
- [ ] `UserManager.remove_user()` removes user
- [ ] `UserManager.reset_token()` generates new token
- [ ] `UserManager.list_users()` returns all users
- [ ] `MultiUserAuthProvider.verify_token()` validates correct token
- [ ] `MultiUserAuthProvider.verify_token()` rejects invalid token
- [ ] `MultiUserAuthProvider.verify_token()` rejects empty token
- [ ] `is_admin_user()` returns True for admin
- [ ] `is_admin_user()` returns False for regular user
- [ ] `APIUserManager` makes correct HTTP requests
- [ ] API endpoints require admin role
- [ ] API endpoints return 501 for non-multi_user auth

### Integration Tests

- [ ] Local user management CLI works
- [ ] Remote user management works via API
- [ ] Docker deployment with persistent storage
- [ ] GCP deployment with GCS storage
- [ ] RunPod deployment with network volumes
- [ ] Root deployment with direct filesystem
- [ ] Data persists across container restarts
- [ ] Users can authenticate with bearer tokens
- [ ] Admin users can access `/api/users/*`
- [ ] Regular users denied from `/api/users/*`

### Security Tests

- [ ] Plaintext tokens never stored in users.yaml
- [ ] users.yaml has 0o600 permissions
- [ ] Token hashes are SHA256
- [ ] Admin endpoints require admin role
- [ ] Invalid tokens are rejected
- [ ] No token expiration (as designed)

---

## Future Enhancements

### Short Term

- [ ] Add user activity logging (create/update/delete operations)
- [ ] Add last login time tracking
- [ ] Implement token rotation (auto-expiring tokens)
- [ ] Add user search/filtering functionality
- [ ] Add bulk user import/export
- [ ] Add user quota/limits management

### Medium Term

- [ ] Per-user isolation (user A cannot see user B's workflows)
- [ ] Fine-grained permissions (read/write/admin for different resources)
- [ ] Add user groups/teams
- [ ] Audit logging for all user actions
- [ ] Backup/restore users file via CLI

### Long Term

- [ ] OAuth provider integration (for SSO)
- [ ] LDAP/Active Directory integration
- [ ] Web UI for user management
- [ ] User invitation system (email tokens)
- [ ] 2FA/TOTP support for admin users
- [ ] SAML SSO integration

---

## References

### Documentation

- **API Server:** `src/nodetool/api/server.py`
- **User Management API:** `src/nodetool/api/users.py`
- **Auth Providers:** `src/nodetool/security/providers/`
- **Admin Auth:** `src/nodetool/security/admin_auth.py`
- **User Manager:** `src/nodetool/security/user_manager.py`
- **API Client:** `src/nodetool/deploy/api_user_manager.py`
- **CLI Commands:** `src/nodetool/cli.py`

### Configuration

- **Deployment Models:** `src/nodetool/config/deployment.py`
- **Environment:** `src/nodetool/config/environment.py`
- **Settings:** `src/nodetool/config/settings.py`

### Deployment

- **Docker Run:** `src/nodetool/deploy/docker_run.py`
- **GCP Deploy:** `src/nodetool/deploy/deploy_to_gcp.py`
- **RunPod Deploy:** `src/nodetool/deploy/deploy_to_runpod.py`

### Testing

- **Test Files:** `tests/test_user_management.py` (created then deleted)
- **Test Location:** `tests/` directory

---

## Implementation Notes

### Code Quality

- **Type Hints:** All new code has proper type annotations
- **Docstrings:** Comprehensive docstrings for all functions/classes
- **Error Handling:** Proper exception handling with helpful messages
- **Logging:** Appropriate logging levels (INFO/WARNING/ERROR)

### Architecture Patterns

- **Factory Pattern:** `UserManager` with configurable users file
- **Strategy Pattern:** Different auth providers (Local, Static, MultiUser, Supabase)
- **Dependency Injection:** Auth providers receive dependencies in constructors
- **Repository Pattern:** `UserManager` abstracts file operations

### Security Best Practices

- **Cryptography:** Using `secrets.token_urlsafe()` for token generation
- **Hashing:** SHA256 for one-way token verification
- **File Permissions:** Explicitly setting 0o600 for sensitive files
- **Input Validation:** Validating all user inputs
- **SQL Injection Prevention:** No SQL queries for user management

### Performance Optimizations

- **File Caching:** `MultiUserAuthProvider` caches users with modification time check
- **Lazy Loading:** Users file only loaded when needed
- **Async Operations:** Using `asyncio` for HTTP requests
- **Connection Pooling:** Reusing HTTP clients for API calls

---

## Summary

**Completed:** 7 Phases (50+ tasks)
- Core auth infrastructure (provider, manager, API, CLI)
- Deployment configuration updates (persistent_paths for all types)
- Integration with API server and existing auth system
- Testing and validation

**Remaining:** 8 Phases (50+ tasks)
- Docker volume mounting and environment variable configuration
- GCP storage mounting and configuration
- RunPod network volume configuration
- Admin route integration
- Documentation and examples
- Error handling improvements

**Estimated Time to Complete:** 4-6 hours of focused work

**Next Priority:** Implement Docker volume mounting (Phase 8) - Critical for data persistence
