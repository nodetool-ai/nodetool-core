"""
Nodetool Help System Module

This module implements the help and documentation system for Nodetool, providing:
- Documentation indexing and searching using ChromaDB for semantic search
- Example workflow indexing and retrieval
- Interactive chat-based help using LLMs
- Core documentation management

Key Components:
- Documentation indexing with semantic and keyword search capabilities
- Example workflow management and search
- Node property lookup and validation
- Interactive chat interface with tool-augmented responses

The module uses ChromaDB for vector storage and retrieval, and integrates with
Ollama for LLM-powered help responses. It supports both semantic and keyword-based
searches across documentation and examples.
"""

import asyncio
import json
import os
from typing import Any, AsyncGenerator, Mapping, List
import readline
import uuid
from nodetool.agents.tools.base import Tool
from nodetool.metadata.node_metadata import NodeMetadata
from pydantic import BaseModel

from jsonschema import validators
from nodetool.chat.providers.base import ChatProvider
from nodetool.config.environment import Environment
import logging
from nodetool.metadata.types import (
    Message,
    MessageTextContent,
    Provider,
    ToolCall,
)
from nodetool.packages.registry import Registry
from nodetool.workflows.types import Chunk
from nodetool.workflows.processing_context import ProcessingContext
from nodetool.chat.providers import get_provider


doc_folder = os.path.join(os.path.dirname(__file__), "docs")
examples = None
documentation = None

log = logging.getLogger(__name__)


def validate_schema(schema):
    meta_schema = validators.Draft7Validator.META_SCHEMA

    # Create a validator
    validator = validators.Draft7Validator(meta_schema)

    try:
        # Validate the schema
        validator.validate(schema)
        print("The schema is valid.")
        return True
    except Exception as e:
        print(f"The schema is invalid. Error: {e}")
        return False


class SearchResult(BaseModel):
    id: str
    content: str
    metadata: Mapping[str, Any] | None = None


registry = Registry()


CORE_DOCS = [
    {
        "id": "models",
        "title": "Models",
        "content": """
        Local Models:
        - Local models need a GPU or MPS to run fast, smaller models can run on CPU
        - Model files can be large, please check your disk space before downloading
        - Remote models require API keys, you can set them in the settings menu

        Remote Models:
        - Remote API Providers require an account and API keys
        - Fal.ai gives access to a wide range of image and video models
        - Replicate gives access to a wide range of models
        - OpenAI and Anthropic models give access to worlds' most powerful language models
        """,
    },
    {
        "id": "assets",
        "title": "Assets",
        "content": """
        Assets:
        - Assets are either uploaded by the user or generated by nodes
        - Drag images, videos, audio, text, or any other files (from FileExplorer / Finder) onto the Asset panel on the right to import them
        - Drag images, videos, audio, text, or any other files onto the canvas to create constant asset nodes
        - Double-click on any asset in a node or inside the ASSETS panel to open it in the AssetViewer
        - Right-click on any asset to open the Asset Menu for more options
        - Select multiple assets by holding CTRL or SHIFT
        - Move assets between folders by dragging them onto the desired folder,
        - or use the right click menu for moving them into nested folders
        - Search for assets by typing in the search bar
        - Sort assets by clicking on the name or date buttons
        - Download: select one or more assets and use the right click menu
        - Delete: right click menu or X button
        - Rename: right click menu or press F2 key (also works with multiple assets)
        """,
    },
    {
        "id": "workflow_basics",
        "title": "Workflow Basics",
        "content": """
        ## Creating Workflows
        - Start with an empty canvas in the workflow editor
        - Add nodes by double-clicking or using CTRL+Space
        - Connect nodes by dragging from output to input handles
        - Configure node parameters in the right panel
        - Save your workflow using the save button
        - Run workflows with the play button
        
        ## Best Practices
        - Name your nodes descriptively
        - Group related nodes together
        - Test workflows incrementally
        - Use comments to document complex parts
        - Back up important workflows
        """,
    },
    {
        "id": "keyboard_shortcuts",
        "title": "Keyboard Shortcuts",
        "content": """
        ## Essential Shortcuts
        - Node Menu: Double-click canvas or Space
        - Run Workflow: CTRL+Enter / Cmd+Enter
        - Stop Workflow: ESC
        - Save: CTRL+S / Cmd+S
        - Undo/Redo: CTRL+Z / Cmd+Z
        - Delete Node: Delete or Backspace
        - Copy/Paste: CTRL+C / CTRL+V / Cmd+C / Cmd+V
        - Select All: CTRL+A / Cmd+A
        - Copy selected nodes: CTRL / âŒ˜ + C and Paste selected nodes with CTRL / âŒ˜ + V
        - Select multiple Nodes: Drag area with left click, Shift + Left Click if using LMB for panning
        - Select multiple nodes: click on nodes with CTRL key or draw a rectangle around nodes
        """,
    },
    {
        "id": "troubleshooting",
        "title": "Troubleshooting",
        "content": """
        ## Common Issues
        - Check model requirements before downloading
        - Verify API keys are correctly set for remote services
        - Ensure sufficient disk space for models
        - Monitor GPU memory usage
        - Check node connections for errors
        
        ## Getting Help
        - Use the help menu (? icon)
        - Check documentation
        - Visit the community forum
        - Report bugs through GitHub
        """,
    },
]


SYSTEM_PROMPT = """
You're an AI assistant for Nodetool, a no-code AI workflow platform. 
YOU ARE CONFIDENT AND KNOWLEDGEABLE.
DO NOT QUESTION YOURSELF.
        
NodeTool enables you to create custom AI workflows on your computer.

## Features âœ¨
- **Visual Editor**: 
  Create AI workflows visually without coding.
  A workflow is a graph of nodes.
  Each node has a name, type, and a set of parameters.
  Nodes can have multiple inputs and outputs.
  The node editor is a canvas that you can use to create your workflows.
  You can connect nodes by dragging from output to input handles.
  You can configure node parameters in the node itself.
  The workflow is executed by evaluating the graph from start to end.
  You can run the workflow by clicking the play button.
  Nodes can take strings, numbers, images, audio, video, and documents as input or output.
  One node is like a python function, it takes input, does something, and produces output.
  Many nodes run AI models, for example a text generation node runs a language model.
- **Local Models**: 
  Run models on your hardware.
  Nodetool's model manager can download models from Hugging Face and other sources.
  AI models need a NVidia GPU or Apple MPS to run fast.
  Nodetool offers many libraries for working with data, images, audio, video, and more.
  For example, image can be edited, audio can be transcribed, and documents can be summarized.
- **Integration with AI Platforms**:
  For more procesing power you can use remote models from OpenAI, Hugging Face, Ollama, Replicate, ElevenLabs, Google, Anthropic, and more.
- **Asset Browser**: 
  Import and manage media assets.
  The assets can be used as input or output for nodes.
  
IMPORTANT NODES:
- Preview Node: Renders any data as a preview, like images, videos, audio, documents, and more.
- Input Nodes: These nodes take user input, like text, images, audio, video, and more.
- Chat Input Node: This node takes user input from a chat interface, including audio, image or documents.
- Constant Node: This node takes a constant value as input, like a string, number, or image.
- Output Node: This node takes any data as input and displays it to the user.
- Loop Node: This node takes list or dataframes and applies a sub graph to each element of the list.
- Text Generation: There are many nodes from different providers for text generation, like OpenAI, Ollama, Google, Anthropic, and more.
- Image Generation: There are many nodes from different providers for image generation, like OpenAI, Hugging Face, Replicate, and more.

## Use Cases ðŸŽ¨
- ðŸŽ¨ **Personal Learning Assistant**: Create chatbots that read and explain your PDFs, e-books, or academic papers
- ðŸ“ **Note Summarization**: Extract key insights from Obsidian or Apple Notes
- ðŸŽ¤ **Voice Memo to Presentation**: Convert recorded ideas into documents
- ðŸ”§ï¸ **Image Generation & Editing**: Create and modify images with advanced AI models
- ðŸŽµ **Audio Processing**: Generate and edit audio content with AI assistance
- ðŸŽ¬ **Video Creation**: Produce and manipulate video content using AI tools
- âš¡ **Automation**: Streamline repetitive tasks with AI-powered scripts

Key Guidelines:
- **Reference Valid Nodes:** When mentioning a node, only reference existing ones. Use the format [Node Type](/help/node_type) for clarity.
- **Use Documentation Search:** Use the documentation search tool to find information about nodes.
- **Use Example Search:** Use the example search tool to find examples of how to use nodes.
- **Answer Precisely:** Be concise, clear, and creative in your responses. Utilize ASCII diagrams if they help explain complex workflows.
- **Focus on Nodetool Features:** Emphasize the visual editor, asset management, model management, workflow execution, and keyboard shortcuts (for example, the help menu in the top right corner).

HOW TO USE SEARCH TOOLS:

1. Semantic Search Documentation:
   - Use semantic_search_documentation() for meaning-based searches
   - Best for conceptual queries and finding related content
   - Example queries:
     - "How to generate images?" -> semantic_search_documentation("image generation")
     - "What nodes can generate text?" -> semantic_search_documentation("text generation")
   - Parameters:
     - query: str - Your search query

2. Keyword Search Documentation:
   - Use keyword_search_documentation() for exact word matches
   - Best for finding specific node types or features
   - Example queries:
     - "What is GPT?" -> keyword_search_documentation("GPT")
     - "How to use Pandas?" -> keyword_search_documentation("Pandas")
   - Parameters:
     - query: str - Your search query

3. Example Search:
   - Use search_examples() to find relevant workflow examples
   - Best for finding example workflows and use cases
   - Example queries:
     - "How to build a chatbot?" -> search_examples("chatbot")
     - "How to build a text to speech workflow?" -> search_examples("text to speech")
   - Parameters:
     - query: str - Your search query
     
4. Node Properties:
   - Use node_properties() to get the properties of a node
   - Best for finding node properties and use cases
   - Example queries:
     - "What are the inputs of the Ollama node?" -> node_properties("Ollama")
     - "What is the output of the ImagePreview node?" -> node_properties("ImagePreview")
   - Parameters:
     - node_type: str - The type of the node

When a user asks a question:
1. First try semantic search to understand the topic
2. If looking for specific nodes/features, use keyword search
3. For implementation examples, use example search
4. For details about a node, use node_properties
5. Combine the results to provide a comprehensive answer

REFERENCE NODES:
- Format any reference to a node as: [Node Type](/help/node_type)
- Example node link: [Text Generation](/help/huggingface.text.TextGeneration)
- DO NOT ADD http/domain to URLs.

HOW TO ANSWER QUESTIONS:
- Explain any necessary Nodetool features
- KEEP IT BRIEF
- DO NOT OVERTHINK
- BE CONCISE
"""


async def create_message(message: Message) -> Mapping[str, str | list[str]]:
    ollama_message: dict[str, str | list[str]] = {
        "role": message.role,
    }

    if isinstance(message.content, list):
        ollama_message["content"] = "\n".join(
            content.text
            for content in message.content
            if isinstance(content, MessageTextContent)
        )
    else:
        ollama_message["content"] = str(message.content)

    return ollama_message


async def create_help_answer(
    provider: ChatProvider, messages: List[Message], model: str
) -> AsyncGenerator[Chunk | ToolCall, None]:
    """
    Generates help answers using a ChatProvider and a set of help-specific tools.
    Streams text chunks of the answer.
    """
    from nodetool.agents.tools.help_tools import (
        SearchNodesTool,
        SearchExamplesTool,
    )

    help_tools_instances: List[Tool] = [
        SearchNodesTool(),
        SearchExamplesTool(),
    ]

    effective_messages_for_provider: List[Message] = [
        Message(role="system", content=SYSTEM_PROMPT)
    ] + messages

    dummy_processing_context = ProcessingContext()  # Create a dummy context

    while True:
        tool_messages_generated_this_iteration: List[Message] = []
        made_tool_call_this_iteration = False

        async for item in provider.generate_messages(
            messages=effective_messages_for_provider,
            model=model,
            tools=help_tools_instances,
        ):  # type: ignore
            if isinstance(item, Chunk):
                yield item
            elif isinstance(item, ToolCall):
                log.info(
                    f"Help system received tool call: {item.name} with args {item.args}"
                )
                yield item

                found_tool_instance = next(
                    (t for t in help_tools_instances if t.name == item.name), None
                )

                tool_call_id = item.id or str(uuid.uuid4())

                if found_tool_instance:
                    tool_args_dict = item.args if isinstance(item.args, dict) else {}
                    if not isinstance(item.args, dict):
                        log.warning(
                            f"Tool call arguments for {item.name} is not a dict: {item.args}. Attempting to use empty dict."
                        )

                    # The process method of BaseHelpTool will handle Pydantic parsing internally
                    try:
                        tool_result_data = await found_tool_instance.process(
                            context=dummy_processing_context,  # Pass dummy context
                            params=tool_args_dict,  # Pass raw dict as params
                        )
                    except Exception as e:
                        log.error(
                            f"Tool call {tool_call_id} ({item.name}) failed with exception: {e}"
                        )
                        # Create an error tool result message
                        tool_result_data = {"error": f"Error executing tool: {str(e)}"}

                    assistant_tool_call_msg = Message(
                        role="assistant", tool_calls=[item]
                    )

                    tool_result_msg = Message(
                        role="tool",
                        tool_call_id=tool_call_id,
                        name=item.name,
                        content=json.dumps(tool_result_data),
                    )
                    tool_messages_generated_this_iteration.extend(
                        [assistant_tool_call_msg, tool_result_msg]
                    )
                    made_tool_call_this_iteration = True
                else:
                    raise ValueError(
                        f"Tool '{item.name}' not found or not a BaseHelpTool instance."
                    )

        if made_tool_call_this_iteration:
            effective_messages_for_provider.extend(
                tool_messages_generated_this_iteration
            )
        else:
            break


async def test_chat(provider: ChatProvider, model: str):
    """Simple terminal-based chat tester with readline support"""
    print("Starting help chat test (type 'exit' to quit)")
    print("This test uses the refactored create_help_answer with a provider.")
    chat_history: List[Message] = []

    readline.parse_and_bind("tab: complete")
    readline.set_completer(lambda text, state: None)

    print(f"Using model: {model}")

    while True:
        try:
            user_input = await asyncio.to_thread(input, "\n> ")
            if user_input.lower() == "exit":
                break
            if not user_input.strip():
                continue

            chat_history.append(Message(role="user", content=user_input))

            full_response = []
            print("Assistant: ", end="", flush=True)
            async for chunk in create_help_answer(
                provider=provider, messages=chat_history, model=model
            ):
                if isinstance(chunk, Chunk):
                    print(chunk.content, end="", flush=True)
                    full_response.append(chunk.content)
                elif isinstance(chunk, ToolCall):
                    print(chunk.name, end="", flush=True)
                    full_response.append(chunk.name)
                else:
                    raise ValueError(f"Unexpected chunk type: {type(chunk)}")
            print()

            if full_response:
                chat_history.append(
                    Message(role="assistant", content="".join(full_response))
                )

        except KeyboardInterrupt:
            print("\nUse 'exit' to quit.")
            continue
        except EOFError:
            print("\nExiting...")
            break
        except Exception as e:
            print(f"\nAn error occurred in test_chat: {e}")


if __name__ == "__main__":
    asyncio.run(test_chat(provider=get_provider(Provider.OpenAI), model="gpt-4o-mini"))
